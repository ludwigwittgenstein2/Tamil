<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.2.269">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Rick Rejeleene">
<meta name="dcterms.date" content="2022-12-15">
<meta name="description" content="A summary of Transformer, successor to RNN Seq2Seq">

<title>Today - Transformers: Easy Tutorial</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1.6em;
  vertical-align: middle;
}
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>


<script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<script src="../../site_libs/quarto-html/quarto.js"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit"
  }
}</script>


<link rel="stylesheet" href="../../styles.css">
</head>

<body class="floating nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg navbar-dark ">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container">
    <a class="navbar-brand" href="../../index.html">
    <span class="navbar-title">Today</span>
    </a>
  </div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item compact">
    <a class="nav-link" href="http://rickrejeleene.me/"><i class="bi bi-house-door-fill" role="img">
</i> 
 <span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://facebook.com/whitekangaroo"><i class="bi bi-facebook" role="img">
</i> 
 <span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://www.linkedin.com/in/rick1776/"><i class="bi bi-linkedin" role="img">
</i> 
 <span class="menu-text"></span></a>
  </li>  
</ul>
              <div id="quarto-search" class="" title="Search"></div>
          </div> <!-- /navcollapse -->
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<header id="title-block-header" class="quarto-title-block default toc-left page-columns page-full">
  <div class="quarto-title-banner page-columns page-full">
    <div class="quarto-title column-body">
      <div class="quarto-title-block"><div><h1 class="title">Transformers: Easy Tutorial</h1><button type="button" class="btn code-tools-button" id="quarto-code-tools-source"><i class="bi"></i> Code</button></div></div>
                  <div>
        <div class="description">
          A summary of Transformer, successor to RNN Seq2Seq
        </div>
      </div>
                          <div class="quarto-categories">
                <div class="quarto-category">Tutorial</div>
                <div class="quarto-category">Machine Learning</div>
                <div class="quarto-category">Easy</div>
              </div>
                  </div>
  </div>
    
  
  <div class="quarto-title-meta">

      <div>
      <div class="quarto-title-meta-heading">Author</div>
      <div class="quarto-title-meta-contents">
               <p>Rick Rejeleene </p>
            </div>
    </div>
      
      <div>
      <div class="quarto-title-meta-heading">Published</div>
      <div class="quarto-title-meta-contents">
        <p class="date">December 15, 2022</p>
      </div>
    </div>
    
      
    </div>
    
  
  </header><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse sidebar-navigation floating overflow-auto">
    <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Contents</h2>
   
  <ul class="collapse">
  <li><a href="#primer-on-transformer" id="toc-primer-on-transformer" class="nav-link active" data-scroll-target="#primer-on-transformer">Primer on Transformer:</a>
  <ul class="collapse">
  <li><a href="#so---what-are-attention-mechanisms-in-baby-steps" id="toc-so---what-are-attention-mechanisms-in-baby-steps" class="nav-link" data-scroll-target="#so---what-are-attention-mechanisms-in-baby-steps">So - What are attention mechanisms in baby steps?</a></li>
  <li><a href="#what-is-the-meat-of-transformer" id="toc-what-is-the-meat-of-transformer" class="nav-link" data-scroll-target="#what-is-the-meat-of-transformer">What is the meat of transformer?</a></li>
  <li><a href="#engineering-attention-mechanism-know-how" id="toc-engineering-attention-mechanism-know-how" class="nav-link" data-scroll-target="#engineering-attention-mechanism-know-how">Engineering Attention Mechanism [know-how]:</a></li>
  <li><a href="#how-to-generate-attention-mechanism" id="toc-how-to-generate-attention-mechanism" class="nav-link" data-scroll-target="#how-to-generate-attention-mechanism">How to generate attention mechanism?</a></li>
  <li><a href="#luong-model" id="toc-luong-model" class="nav-link" data-scroll-target="#luong-model">Luong Model:</a></li>
  <li><a href="#describing-in-plain-english" id="toc-describing-in-plain-english" class="nav-link" data-scroll-target="#describing-in-plain-english">Describing in plain english:</a></li>
  <li><a href="#self-attention" id="toc-self-attention" class="nav-link" data-scroll-target="#self-attention">Self-attention:</a></li>
  <li><a href="#multi-head-attention" id="toc-multi-head-attention" class="nav-link" data-scroll-target="#multi-head-attention">Multi-Head Attention:</a></li>
  </ul></li>
  <li><a href="#so-what-does-it-do" id="toc-so-what-does-it-do" class="nav-link" data-scroll-target="#so-what-does-it-do">So, What does it do?</a></li>
  <li><a href="#what-does-it-do" id="toc-what-does-it-do" class="nav-link" data-scroll-target="#what-does-it-do">What does it do?</a>
  <ul class="collapse">
  <li><a href="#positional-encoding" id="toc-positional-encoding" class="nav-link" data-scroll-target="#positional-encoding">Positional Encoding:</a></li>
  </ul></li>
  <li><a href="#tokenization" id="toc-tokenization" class="nav-link" data-scroll-target="#tokenization">Tokenization:</a></li>
  <li><a href="#what-is-it" id="toc-what-is-it" class="nav-link" data-scroll-target="#what-is-it">What is it?</a></li>
  <li><a href="#bert" id="toc-bert" class="nav-link" data-scroll-target="#bert">BERT</a></li>
  <li><a href="#conclusion" id="toc-conclusion" class="nav-link" data-scroll-target="#conclusion">Conclusion</a></li>
  </ul>
</nav>
</nav>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
    </div>
<!-- main -->
<main class="content quarto-banner-title-block" id="quarto-document-content">




<section id="primer-on-transformer" class="level1">
<h1>Primer on Transformer:</h1>
<p>Anyone who has conversation about Machine Learning or AI, or is interested, can read it to understand. Transformers are a type of Machine learning model, based on variant of self-attention mechanism.</p>
<ol type="1">
<li>Transformers replaced using, ‚Äúattention‚Äù mechanism</li>
<li>No convolutional layer or recurrent layer used in Transformer</li>
<li>As of now ‚Äì Transformers are used in state of art technology</li>
</ol>
<blockquote class="blockquote">
<p>Pre-requisite for Transformers: Engineering Math</p>
</blockquote>
<p>Well, Did we think we could skip Mathematics? Do we recall our high school teacher, who stressed importance of mathematics? Many components in Machine learning are built from mathematical tools.</p>
<section id="so---what-are-attention-mechanisms-in-baby-steps" class="level2">
<h2 class="anchored" data-anchor-id="so---what-are-attention-mechanisms-in-baby-steps">So - What are attention mechanisms in baby steps?</h2>
<ol type="1">
<li>We can think of them as vector of relevance in a sequence</li>
<li>Attention Mechanisms creates a score at the end</li>
<li>These scores, are generated dynamically at each time step, t</li>
<li>With this, Transformers has the power to understand bi-directionality in sentence</li>
</ol>
</section>
<section id="what-is-the-meat-of-transformer" class="level2">
<h2 class="anchored" data-anchor-id="what-is-the-meat-of-transformer">What is the meat of transformer?</h2>
<p>The Core part of Transformers is Attention Mechanism:</p>
<p>Previously, before transformers were introduced circa 2016-2017. For Sequence to Sequence tasks, meaning, convert [Tamil] to [English] task eg:‚ÄúNa Veetuku Porae‚Äù [Tamil], ‚ÄúI house go‚Äù [English]</p>
<p>This is literal translation of a sentence.</p>
<p>The actual translation is, ‚ÄúI am going to house‚Äù</p>
<p>So, we want our translation to be as accurate as possible - right? Encoder-Decoder Architectures were primarily the leading architecture in Sequence to Sequence tasks.</p>
<p>In Encoder-Decoder, we had fixed vector. This limited to understand context of the sentences. So in attention, we have a context vector, in-between Encoder-Decoder What is context vector? [yellow in image]</p>
<p>Basically, previously we had a fixed size vector representation of encoder</p>
<p>Issue of this approach:</p>
<ol type="1">
<li>That doesn‚Äôt give me information about entire sentence</li>
<li>Each step, different information from sentence is relevant So, Solution: ‚ÄúAttention Mechanism‚Äù</li>
<li>At each step, attention mechanism allows model to focus on different parts</li>
</ol>
<p>At each decoder step, 1) Receive input, decoder state h(t) and all encoder states s(1), s(2)‚Ä¶ s(m) 2) Compute a score for Attention, 3) At each encoder state, s(k), compute relevance for decoder state h(t) 4) Apply attention function, meaning, (receive one decoder state, and one encoder state) 5) Return a scalar value, score(h[t], s[k]) 6) Compute Attention Weight, which is a probability distribution 7) Compute Attention Output, weighted sum of encoder state with attention weight</p>
</section>
<section id="engineering-attention-mechanism-know-how" class="level2">
<h2 class="anchored" data-anchor-id="engineering-attention-mechanism-know-how">Engineering Attention Mechanism [know-how]:</h2>
</section>
<section id="how-to-generate-attention-mechanism" class="level2">
<h2 class="anchored" data-anchor-id="how-to-generate-attention-mechanism">How to generate attention mechanism?</h2>
<p>Baby Steps in order: 1. Attention Input: [All Encoder State, S1‚Ä¶. Sm] and One Decoder State, H(t) 2. Attention Score: Score(h[t], s[k]), k=1‚Ä¶.m 3. Softmax 4. Attention Weights, a subscript (k) superscript (t) = exp( score(h[t], s[k])) / Summation of i=1 to m exp(score(h[t], s[i])), k=1‚Ä¶m 5. Context Vector c (t) = a1 s1 + a2 s2 + ‚Ä¶. + a(m)[t] S(m) Summation of k = 1 to m, a (k)[t] to s(k) All steps is differentiable. Intuition: Neural Network learns, which input parts are important at each step.</p>
<p>So, that was building block steps.</p>
<p>How to compute scores in Attention Mechanism? In papers, there‚Äôs Bahdanau, Luong and others. There‚Äôs variants in Attention Function scores 1. dot-product 2. bilinear function 3. multi-layer perceptron [bahdanau]</p>
<p>Variants in Attention Mechanism:</p>
<p>Bahdanau:</p>
<ol type="1">
<li>Encoder - Bidirectional RNN There‚Äôs two RNN‚Äôs</li>
</ol>
<p>Forward Backward</p>
<ol start="2" type="1">
<li><p>Attention Score: Multi-layer perceptron Apply MLP between encoder and decoder to get attention score</p></li>
<li><p>Attention Applied between Decoder Steps Attention, between decoder steps, state h(t-1), compute attention, output c(t)</p></li>
<li><p>Both h(t-1) and c(t) is passed to decoder at step (t)</p></li>
</ol>
</section>
<section id="luong-model" class="level2">
<h2 class="anchored" data-anchor-id="luong-model">Luong Model:</h2>
<ol type="1">
<li>Encoder: unidirectional</li>
<li>Attention Score: Bilinear function</li>
<li>Attention Applied between decoder RNN State t and prediction for this step Attention is used after RNN decoder step (t), before prediction State h(t) used to compute attention, and output c(t) H(t) combined with c(t) to get updated representation h(t)</li>
</ol>
<p>While ‚Äì this is frequently used in papers. What is this? 1. Scores of relevance at each time step 2. Dynamically generated</p>
</section>
<section id="describing-in-plain-english" class="level2">
<h2 class="anchored" data-anchor-id="describing-in-plain-english">Describing in plain english:</h2>
<ol type="1">
<li>Encoder is containing, with all source tokens</li>
<li>And, what are they doing?</li>
<li>Look at each other, update representations</li>
<li>Decoder is doing, look at target token at current time step (t)</li>
<li>Look at previous target token, look at source representation</li>
<li>Update representation</li>
</ol>
</section>
<section id="self-attention" class="level2">
<h2 class="anchored" data-anchor-id="self-attention">Self-attention:</h2>
<p>Self-attention is a key-building block What‚Äôs the diff between self-attention vs attention? Huh, Well - self-attention operates between representation of same nature</p>
<p>Decoder-encoder attention is looking From: one current decoder state At: all encoder states Self-attention is looking From: each state from a set of states At: All other states in same set</p>
<p>Query, Key and Value in Self-Attention: QKV, is how we implement attention. Each input token, in self-attention receives three representation So- what do Q, K, V do? 1. Query : I Ask for an information 2. Key: I have some information 3. Value: I give you the information Query ‚Äì Tokens look at each other Key ‚Äì Respond to Query‚Äôs request Value ‚Äì Compute Attention Output</p>
<p>Key idea to remember, ‚ÄúCompare Query with Keys‚Äù to get, ‚ÄúScores/Weights‚Äù for, ‚ÄúValues‚Äù 1. Each Score/Weight is relevance between query, key 2. Reweigh values with scores/weights 3. Take summation of reweighed values Multi-head Attention</p>
</section>
<section id="multi-head-attention" class="level2">
<h2 class="anchored" data-anchor-id="multi-head-attention">Multi-Head Attention:</h2>
<p>The Building Block of Transformer Model: In order to understand a word in a sentence, It requires understanding, how is this word related in a sentence eg: ‚ÄúNa Veetuku Porae‚Äù [Tamil] to I am going to my house [English] Requires knowing, ‚ÄúVeetuku‚Äù word, on how is it related to other words in a sentence. So, Each word has relations So Intuitively, Multi-head attention, lets the model focus on many things.</p>
<p>So, we split queries, keys, values of single-head attention into several parts. In this way ‚Äì model with one attention head or several of them, have same size.</p>
<p>Now for Transformer Model: Source: Lena Voita‚Äôs Blog</p>
</section>
</section>
<section id="so-what-does-it-do" class="level1">
<h1>So, What does it do?</h1>
<ol type="1">
<li>Encoder ‚Äì token communicates with each other</li>
<li>Update Representation</li>
<li>Decoder, target token look at previously generate target token</li>
<li>Update Representation</li>
<li>We have 6 layers Feed Forward Layer: The Model uses FFL to update new information</li>
</ol>
<section id="residual-connections" class="level3">
<h3 class="anchored" data-anchor-id="residual-connections">Residual Connections:</h3>
<p>First time, I saw this - it was in Object detection papers. Why use it? Similar to skip-connection Stabilize the network Recall, when we have deeper neural networks, issues start ebbing out ‚ÄúVanishing Gradient‚Äù - suddenly, the training drops to, ‚ÄúZero‚Äù Imagine, you are in your house, lights are on, suddenly it becomes dark. That‚Äôs why, similar to Skip-connection, Residual connection</p>
<p>In Transformer:</p>
<p>Residuals used after Attention and Feed Forward Neural Network block Layer Normalization: Norm in Transformer ‚ÄúAdd &amp; Norm‚Äù is Layer Normalization</p>
</section>
</section>
<section id="what-does-it-do" class="level1">
<h1>What does it do?</h1>
<p>Well, it normalizes, vector representation in batches</p>
<p>So what? Well, We want to manage flow to next layer Layer normalization improves convergence stability and quality</p>
<ol type="1">
<li>Normalize each vector representation of each token</li>
<li>LayerNorm, has parameters - scale and bias</li>
</ol>
<section id="positional-encoding" class="level2">
<h2 class="anchored" data-anchor-id="positional-encoding">Positional Encoding:</h2>
<p>Recall, we want some sort of representation for positions of tokens Convolutional Layers or Recurrence Layers They help to know position of tokens But, in Transformer, we do not have either, So, we need something for positional representation.</p>
<p>Two embedding are required:</p>
<p>Embedding, a way to translate words into magic vector form, so computers can understand 1) Tokens 2) Positions So, input representation of token is sum of two embeddings: Token and Positional</p>
<p>Pos is position. i is vector dimension. If you recall, trigonometry from your math teacher in high-school. Trigonometric functions are helpful to represent angles, position. How cool is it? Positional Encoding, represents wavelengths in geometric progression from 2‚àè to 1000. 2‚àè. Think this way - a way to represent positions through angles So what? eg: ‚ÄúRoom la fan poddu‚Äù [Tamil] translates, Switch on Fan [English] ‚Äúpoddu‚Äù can be break or to turn on. Positional Encoding, would help represent and retain both meanings.</p>
</section>
</section>
<section id="tokenization" class="level1">
<h1>Tokenization:</h1>
</section>
<section id="what-is-it" class="level1">
<h1>What is it?</h1>
<p>A way to divide sequence of words into small pieces Many types are there So, ‚ÄúPoddu‚Äù [Tamil] word has both turn on, and to break meaning 1. Word Level 2. Sub-word Level Word Level can only process fixed number of words, limited Subword level can process open vocabulary, and unknown words</p>
<p>Baby step High-level differences between Encoder-Decoder in Transformer: Encoder: 1. Multi-head Attention Decoder: 1. Masked Multi-head Attention 2. Scaled Dot-Product Attention Recall, Masked Self-attention means, future tokens are masked out.</p>
<p>Another way to explain, more picture focused (Attention Layer): GRU:</p>
<ol type="1">
<li>Recall, GRU is specialized form of RNN</li>
<li>GRU has two gates [reset, update]</li>
<li>LSTM has three gates [input, output, forget] GRU, less complex than LSTM</li>
<li>GRU, doesn‚Äôt have memory unit compared with LSTM</li>
</ol>
<p>So in the picture, Encoder-Decoder, dominant form of architecture in Seq2Seq task, cool right? BiGRU, Bidirectional GRU, takes input in forward and other in backward direction Green Dots ‚Äì Encoder Hidden State Red Dots ‚Äì Decoder Hidden State Why do we need Hidden State? Squashing function, perform non-linear function in neural network Blue dots ‚Äì Score Softmax ‚Äì Sum of probability distribution equal to 1 Use Softmax only when in classifier, classes are mutually exclusive Alignment Vector ‚Äì input at position j, and outputs at position i match Context Vector ‚Äì Attention Score Source: [Teksands]</p>
<p>Scaled Dot Product Attention Score = (1/‚àön) (decoder state) (encoder state) Dot Product Attention: Score = (decoder state) (encoder state) Additive based Attention Score = (decoder state) (encoder state) = trainable weights Cosine Similarity based Attention: Score = (decoder state) (encoder state) / norm [(decoder state) (encoder state)] Source: [Teksands]</p>
</section>
<section id="bert" class="level1">
<h1>BERT</h1>
<ol type="1">
<li>Pre-trained Language Model from Google</li>
<li>Most easy to use among all language models BERT lead into developments in</li>
<li>GPT (Decoder Block)</li>
<li>GPT-2 (Decoder Block)</li>
<li>GPT-3 (Decoder Block) Where to start? ‚ÄúAttention is all you need‚Äù Paper: üìéhttps://arxiv.org/pdf/1706.03762.pdf Tutorial: https://nlp.seas.harvard.edu/2018/04/03/attention.html Harvard NLP Professor Stuart Shieber‚Äôs Blog üßµ</li>
</ol>
</section>
<section id="conclusion" class="level1">
<h1>Conclusion</h1>
<p>It is easy to create great looking documents using <code>quarto</code>, whether that be with code in <code>python</code> or <code>R</code>. <code>Quarto</code> supports most of the features in <code>RMarkdown</code> with some fancy new ones. My personal favourite is the floating table of contents. I have also found that rendering a <code>Quarto</code> blog is a much smoother experience than rendering a <code>blogdown</code> blog.</p>


<!-- -->

</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "Óßã";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    target: function(trigger) {
      return trigger.previousElementSibling;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  const viewSource = window.document.getElementById('quarto-view-source') ||
                     window.document.getElementById('quarto-code-tools-source');
  if (viewSource) {
    const sourceUrl = viewSource.getAttribute("data-quarto-source-url");
    viewSource.addEventListener("click", function(e) {
      if (sourceUrl) {
        // rstudio viewer pane
        if (/\bcapabilities=\b/.test(window.location)) {
          window.open(sourceUrl);
        } else {
          window.location.href = sourceUrl;
        }
      } else {
        const modal = new bootstrap.Modal(document.getElementById('quarto-embedded-source-code-modal'));
        modal.show();
      }
      return false;
    });
  }
  function toggleCodeHandler(show) {
    return function(e) {
      const detailsSrc = window.document.querySelectorAll(".cell > details > .sourceCode");
      for (let i=0; i<detailsSrc.length; i++) {
        const details = detailsSrc[i].parentElement;
        if (show) {
          details.open = true;
        } else {
          details.removeAttribute("open");
        }
      }
      const cellCodeDivs = window.document.querySelectorAll(".cell > .sourceCode");
      const fromCls = show ? "hidden" : "unhidden";
      const toCls = show ? "unhidden" : "hidden";
      for (let i=0; i<cellCodeDivs.length; i++) {
        const codeDiv = cellCodeDivs[i];
        if (codeDiv.classList.contains(fromCls)) {
          codeDiv.classList.remove(fromCls);
          codeDiv.classList.add(toCls);
        } 
      }
      return false;
    }
  }
  const hideAllCode = window.document.getElementById("quarto-hide-all-code");
  if (hideAllCode) {
    hideAllCode.addEventListener("click", toggleCodeHandler(false));
  }
  const showAllCode = window.document.getElementById("quarto-show-all-code");
  if (showAllCode) {
    showAllCode.addEventListener("click", toggleCodeHandler(true));
  }
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script><div class="modal fade" id="quarto-embedded-source-code-modal" tabindex="-1" aria-labelledby="quarto-embedded-source-code-modal-label" aria-hidden="true"><div class="modal-dialog modal-dialog-scrollable"><div class="modal-content"><div class="modal-header"><h5 class="modal-title" id="quarto-embedded-source-code-modal-label">Source Code</h5><button class="btn-close" data-bs-dismiss="modal"></button></div><div class="modal-body"><div class="">
<div class="sourceCode" id="cb1" data-shortcodes="false"><pre class="sourceCode markdown code-with-copy"><code class="sourceCode markdown"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="co">---</span></span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="an">title:</span><span class="co"> 'Transformers: Easy Tutorial'</span></span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="an">author:</span><span class="co"> Rick Rejeleene</span></span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="an">date:</span><span class="co"> '2022-12-15'</span></span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="an">categories:</span></span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a><span class="co">  - Tutorial </span></span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a><span class="co">  - Machine Learning</span></span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a><span class="co">  - Easy</span></span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a><span class="an">draft:</span><span class="co"> true</span></span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a><span class="an">description:</span><span class="co"> 'A summary of Transformer, successor to RNN Seq2Seq'</span></span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a><span class="an">image:</span><span class="co"> ""</span></span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a><span class="an">archives:</span></span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a><span class="co">  - 2022/08</span></span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a><span class="an">toc:</span><span class="co"> true</span></span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a><span class="an">toc-depth:</span><span class="co"> 2</span></span>
<span id="cb1-16"><a href="#cb1-16" aria-hidden="true" tabindex="-1"></a><span class="an">toc-location:</span><span class="co"> left</span></span>
<span id="cb1-17"><a href="#cb1-17" aria-hidden="true" tabindex="-1"></a><span class="an">toc-title:</span><span class="co"> Contents</span></span>
<span id="cb1-18"><a href="#cb1-18" aria-hidden="true" tabindex="-1"></a><span class="co">  </span></span>
<span id="cb1-19"><a href="#cb1-19" aria-hidden="true" tabindex="-1"></a><span class="an">format:</span><span class="co"> </span></span>
<span id="cb1-20"><a href="#cb1-20" aria-hidden="true" tabindex="-1"></a><span class="co">  html: </span></span>
<span id="cb1-21"><a href="#cb1-21" aria-hidden="true" tabindex="-1"></a><span class="co">    code-fold: show</span></span>
<span id="cb1-22"><a href="#cb1-22" aria-hidden="true" tabindex="-1"></a><span class="co">    code-tools: true</span></span>
<span id="cb1-23"><a href="#cb1-23" aria-hidden="true" tabindex="-1"></a><span class="co">    code-link: true</span></span>
<span id="cb1-24"><a href="#cb1-24" aria-hidden="true" tabindex="-1"></a><span class="an">bibliography:</span><span class="co"> references.bib</span></span>
<span id="cb1-25"><a href="#cb1-25" aria-hidden="true" tabindex="-1"></a><span class="an">link-citations:</span><span class="co"> true</span></span>
<span id="cb1-26"><a href="#cb1-26" aria-hidden="true" tabindex="-1"></a><span class="co">---</span></span>
<span id="cb1-27"><a href="#cb1-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-28"><a href="#cb1-28" aria-hidden="true" tabindex="-1"></a><span class="fu"># Primer on Transformer:</span></span>
<span id="cb1-29"><a href="#cb1-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-30"><a href="#cb1-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-31"><a href="#cb1-31" aria-hidden="true" tabindex="-1"></a>Anyone who has conversation about Machine Learning or AI, or is interested, can read it to understand.</span>
<span id="cb1-32"><a href="#cb1-32" aria-hidden="true" tabindex="-1"></a>Transformers are a type of Machine learning model, based on variant of self-attention mechanism. </span>
<span id="cb1-33"><a href="#cb1-33" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-34"><a href="#cb1-34" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-35"><a href="#cb1-35" aria-hidden="true" tabindex="-1"></a><span class="ss">1. </span>Transformers replaced using, "attention" mechanism</span>
<span id="cb1-36"><a href="#cb1-36" aria-hidden="true" tabindex="-1"></a><span class="ss">2. </span>No convolutional layer or recurrent layer used in Transformer</span>
<span id="cb1-37"><a href="#cb1-37" aria-hidden="true" tabindex="-1"></a><span class="ss">3. </span>As of now -- Transformers are used in state of art technology</span>
<span id="cb1-38"><a href="#cb1-38" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-39"><a href="#cb1-39" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-40"><a href="#cb1-40" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; Pre-requisite for Transformers: Engineering Math</span></span>
<span id="cb1-41"><a href="#cb1-41" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-42"><a href="#cb1-42" aria-hidden="true" tabindex="-1"></a>Well, Did we think we could skip Mathematics? </span>
<span id="cb1-43"><a href="#cb1-43" aria-hidden="true" tabindex="-1"></a>Do we recall our high school teacher, who stressed importance of mathematics? </span>
<span id="cb1-44"><a href="#cb1-44" aria-hidden="true" tabindex="-1"></a>Many components in Machine learning are built from mathematical tools.</span>
<span id="cb1-45"><a href="#cb1-45" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-46"><a href="#cb1-46" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-47"><a href="#cb1-47" aria-hidden="true" tabindex="-1"></a><span class="fu">## So - What are attention mechanisms in baby steps?</span></span>
<span id="cb1-48"><a href="#cb1-48" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-49"><a href="#cb1-49" aria-hidden="true" tabindex="-1"></a><span class="ss">1. </span>We can think of them as vector of relevance in a sequence</span>
<span id="cb1-50"><a href="#cb1-50" aria-hidden="true" tabindex="-1"></a><span class="ss">2. </span>Attention Mechanisms creates a score at the end</span>
<span id="cb1-51"><a href="#cb1-51" aria-hidden="true" tabindex="-1"></a><span class="ss">3. </span>These scores, are generated dynamically at each time step, t</span>
<span id="cb1-52"><a href="#cb1-52" aria-hidden="true" tabindex="-1"></a><span class="ss">4. </span>With this, Transformers has the power to understand bi-directionality in sentence</span>
<span id="cb1-53"><a href="#cb1-53" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-54"><a href="#cb1-54" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-55"><a href="#cb1-55" aria-hidden="true" tabindex="-1"></a><span class="fu">## What is the meat of transformer? </span></span>
<span id="cb1-56"><a href="#cb1-56" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-57"><a href="#cb1-57" aria-hidden="true" tabindex="-1"></a>The Core part of Transformers is Attention Mechanism:</span>
<span id="cb1-58"><a href="#cb1-58" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-59"><a href="#cb1-59" aria-hidden="true" tabindex="-1"></a>Previously, before transformers were introduced circa 2016-2017.</span>
<span id="cb1-60"><a href="#cb1-60" aria-hidden="true" tabindex="-1"></a>For Sequence to Sequence tasks, meaning, convert <span class="co">[</span><span class="ot">Tamil</span><span class="co">]</span> to <span class="co">[</span><span class="ot">English</span><span class="co">]</span> task</span>
<span id="cb1-61"><a href="#cb1-61" aria-hidden="true" tabindex="-1"></a>eg:"Na Veetuku Porae" <span class="co">[</span><span class="ot">Tamil</span><span class="co">]</span>, "I house go" <span class="co">[</span><span class="ot">English</span><span class="co">]</span></span>
<span id="cb1-62"><a href="#cb1-62" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-63"><a href="#cb1-63" aria-hidden="true" tabindex="-1"></a>This is literal translation of a sentence.</span>
<span id="cb1-64"><a href="#cb1-64" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-65"><a href="#cb1-65" aria-hidden="true" tabindex="-1"></a>The actual translation is, "I am going to house"</span>
<span id="cb1-66"><a href="#cb1-66" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-67"><a href="#cb1-67" aria-hidden="true" tabindex="-1"></a>So, we want our translation to be as accurate as possible - right?</span>
<span id="cb1-68"><a href="#cb1-68" aria-hidden="true" tabindex="-1"></a>Encoder-Decoder Architectures were primarily the leading architecture in Sequence to Sequence tasks.</span>
<span id="cb1-69"><a href="#cb1-69" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-70"><a href="#cb1-70" aria-hidden="true" tabindex="-1"></a>In Encoder-Decoder, we had fixed vector. This limited to understand context of the sentences.</span>
<span id="cb1-71"><a href="#cb1-71" aria-hidden="true" tabindex="-1"></a>So in attention, we have a context vector, in-between Encoder-Decoder</span>
<span id="cb1-72"><a href="#cb1-72" aria-hidden="true" tabindex="-1"></a>What is context vector? <span class="co">[</span><span class="ot">yellow in image</span><span class="co">]</span></span>
<span id="cb1-73"><a href="#cb1-73" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-74"><a href="#cb1-74" aria-hidden="true" tabindex="-1"></a>Basically, previously we had a fixed size vector representation of encoder</span>
<span id="cb1-75"><a href="#cb1-75" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-76"><a href="#cb1-76" aria-hidden="true" tabindex="-1"></a>Issue of this approach:</span>
<span id="cb1-77"><a href="#cb1-77" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-78"><a href="#cb1-78" aria-hidden="true" tabindex="-1"></a><span class="ss">1. </span>That doesn't give me information about entire sentence</span>
<span id="cb1-79"><a href="#cb1-79" aria-hidden="true" tabindex="-1"></a><span class="ss">2. </span>Each step, different information from sentence is relevant</span>
<span id="cb1-80"><a href="#cb1-80" aria-hidden="true" tabindex="-1"></a>So, Solution: "Attention Mechanism"</span>
<span id="cb1-81"><a href="#cb1-81" aria-hidden="true" tabindex="-1"></a><span class="ss">1. </span>At each step, attention mechanism allows model to focus on different parts</span>
<span id="cb1-82"><a href="#cb1-82" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-83"><a href="#cb1-83" aria-hidden="true" tabindex="-1"></a>At each decoder step,</span>
<span id="cb1-84"><a href="#cb1-84" aria-hidden="true" tabindex="-1"></a>1) Receive input, decoder state h(t) and all encoder states s(1), s(2)... s(m)</span>
<span id="cb1-85"><a href="#cb1-85" aria-hidden="true" tabindex="-1"></a>2) Compute a score for Attention,</span>
<span id="cb1-86"><a href="#cb1-86" aria-hidden="true" tabindex="-1"></a>3) At each encoder state, s(k), compute relevance for decoder state h(t)</span>
<span id="cb1-87"><a href="#cb1-87" aria-hidden="true" tabindex="-1"></a>4) Apply attention function, meaning, (receive one decoder state, and one encoder state)</span>
<span id="cb1-88"><a href="#cb1-88" aria-hidden="true" tabindex="-1"></a>5) Return a scalar value, score(h<span class="co">[</span><span class="ot">t</span><span class="co">]</span>, s<span class="co">[</span><span class="ot">k</span><span class="co">]</span>)</span>
<span id="cb1-89"><a href="#cb1-89" aria-hidden="true" tabindex="-1"></a>6) Compute Attention Weight, which is a probability distribution</span>
<span id="cb1-90"><a href="#cb1-90" aria-hidden="true" tabindex="-1"></a>7) Compute Attention Output, weighted sum of encoder state with attention weight</span>
<span id="cb1-91"><a href="#cb1-91" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-92"><a href="#cb1-92" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-93"><a href="#cb1-93" aria-hidden="true" tabindex="-1"></a><span class="fu">## Engineering Attention Mechanism [know-how]:</span></span>
<span id="cb1-94"><a href="#cb1-94" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-95"><a href="#cb1-95" aria-hidden="true" tabindex="-1"></a><span class="fu">## How to generate attention mechanism?</span></span>
<span id="cb1-96"><a href="#cb1-96" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-97"><a href="#cb1-97" aria-hidden="true" tabindex="-1"></a>Baby Steps in order:</span>
<span id="cb1-98"><a href="#cb1-98" aria-hidden="true" tabindex="-1"></a><span class="ss">1. </span>Attention Input: <span class="co">[</span><span class="ot">All Encoder State, S1.... Sm</span><span class="co">]</span> and One Decoder State, H(t)</span>
<span id="cb1-99"><a href="#cb1-99" aria-hidden="true" tabindex="-1"></a><span class="ss">2. </span>Attention Score: Score(h<span class="co">[</span><span class="ot">t</span><span class="co">]</span>, s<span class="co">[</span><span class="ot">k</span><span class="co">]</span>), k=1....m</span>
<span id="cb1-100"><a href="#cb1-100" aria-hidden="true" tabindex="-1"></a><span class="ss">3. </span>Softmax</span>
<span id="cb1-101"><a href="#cb1-101" aria-hidden="true" tabindex="-1"></a><span class="ss">4. </span>Attention Weights, a subscript (k) superscript (t)</span>
<span id="cb1-102"><a href="#cb1-102" aria-hidden="true" tabindex="-1"></a>= exp( score(h<span class="co">[</span><span class="ot">t</span><span class="co">]</span>, s<span class="co">[</span><span class="ot">k</span><span class="co">]</span>)) / Summation of i=1 to m exp(score(h<span class="co">[</span><span class="ot">t</span><span class="co">]</span>, s<span class="co">[</span><span class="ot">i</span><span class="co">]</span>)), k=1...m</span>
<span id="cb1-103"><a href="#cb1-103" aria-hidden="true" tabindex="-1"></a><span class="ss">5. </span>Context Vector c (t) = a1 s1 + a2 s2 + .... + a(m)<span class="co">[</span><span class="ot">t</span><span class="co">]</span> S(m)</span>
<span id="cb1-104"><a href="#cb1-104" aria-hidden="true" tabindex="-1"></a>Summation of k = 1 to m, a (k)<span class="co">[</span><span class="ot">t</span><span class="co">]</span> to s(k)</span>
<span id="cb1-105"><a href="#cb1-105" aria-hidden="true" tabindex="-1"></a>All steps is differentiable.</span>
<span id="cb1-106"><a href="#cb1-106" aria-hidden="true" tabindex="-1"></a>Intuition: Neural Network learns, which input parts are important at each step.</span>
<span id="cb1-107"><a href="#cb1-107" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-108"><a href="#cb1-108" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-109"><a href="#cb1-109" aria-hidden="true" tabindex="-1"></a>So, that was building block steps.</span>
<span id="cb1-110"><a href="#cb1-110" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-111"><a href="#cb1-111" aria-hidden="true" tabindex="-1"></a>How to compute scores in Attention Mechanism?</span>
<span id="cb1-112"><a href="#cb1-112" aria-hidden="true" tabindex="-1"></a>In papers, there's Bahdanau, Luong and others.</span>
<span id="cb1-113"><a href="#cb1-113" aria-hidden="true" tabindex="-1"></a>There's variants in Attention Function scores</span>
<span id="cb1-114"><a href="#cb1-114" aria-hidden="true" tabindex="-1"></a><span class="ss">1. </span>dot-product</span>
<span id="cb1-115"><a href="#cb1-115" aria-hidden="true" tabindex="-1"></a><span class="ss">2. </span>bilinear function</span>
<span id="cb1-116"><a href="#cb1-116" aria-hidden="true" tabindex="-1"></a><span class="ss">3. </span>multi-layer perceptron <span class="co">[</span><span class="ot">bahdanau</span><span class="co">]</span></span>
<span id="cb1-117"><a href="#cb1-117" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-118"><a href="#cb1-118" aria-hidden="true" tabindex="-1"></a>Variants in Attention Mechanism:</span>
<span id="cb1-119"><a href="#cb1-119" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-120"><a href="#cb1-120" aria-hidden="true" tabindex="-1"></a>Bahdanau:</span>
<span id="cb1-121"><a href="#cb1-121" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-122"><a href="#cb1-122" aria-hidden="true" tabindex="-1"></a><span class="ss">1. </span>Encoder - Bidirectional RNN</span>
<span id="cb1-123"><a href="#cb1-123" aria-hidden="true" tabindex="-1"></a>There's two RNN's</span>
<span id="cb1-124"><a href="#cb1-124" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-125"><a href="#cb1-125" aria-hidden="true" tabindex="-1"></a>Forward</span>
<span id="cb1-126"><a href="#cb1-126" aria-hidden="true" tabindex="-1"></a>Backward</span>
<span id="cb1-127"><a href="#cb1-127" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-128"><a href="#cb1-128" aria-hidden="true" tabindex="-1"></a><span class="ss">2. </span>Attention Score: Multi-layer perceptron</span>
<span id="cb1-129"><a href="#cb1-129" aria-hidden="true" tabindex="-1"></a>Apply MLP between encoder and decoder to get attention score</span>
<span id="cb1-130"><a href="#cb1-130" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-131"><a href="#cb1-131" aria-hidden="true" tabindex="-1"></a><span class="ss">3. </span>Attention Applied between Decoder Steps</span>
<span id="cb1-132"><a href="#cb1-132" aria-hidden="true" tabindex="-1"></a>Attention, between decoder steps, state h(t-1), compute attention, output c(t)</span>
<span id="cb1-133"><a href="#cb1-133" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-134"><a href="#cb1-134" aria-hidden="true" tabindex="-1"></a><span class="ss">4. </span>Both h(t-1) and c(t) is passed to decoder at step (t)</span>
<span id="cb1-135"><a href="#cb1-135" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-136"><a href="#cb1-136" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-137"><a href="#cb1-137" aria-hidden="true" tabindex="-1"></a><span class="fu">## Luong Model:</span></span>
<span id="cb1-138"><a href="#cb1-138" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-139"><a href="#cb1-139" aria-hidden="true" tabindex="-1"></a><span class="ss">1. </span>Encoder: unidirectional</span>
<span id="cb1-140"><a href="#cb1-140" aria-hidden="true" tabindex="-1"></a><span class="ss">2. </span>Attention Score: Bilinear function</span>
<span id="cb1-141"><a href="#cb1-141" aria-hidden="true" tabindex="-1"></a><span class="ss">3. </span>Attention Applied between decoder RNN State t and prediction for this step</span>
<span id="cb1-142"><a href="#cb1-142" aria-hidden="true" tabindex="-1"></a>Attention is used after RNN decoder step (t), before prediction</span>
<span id="cb1-143"><a href="#cb1-143" aria-hidden="true" tabindex="-1"></a>State h(t) used to compute attention, and output c(t)</span>
<span id="cb1-144"><a href="#cb1-144" aria-hidden="true" tabindex="-1"></a>H(t) combined with c(t) to get updated representation h(t)</span>
<span id="cb1-145"><a href="#cb1-145" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-146"><a href="#cb1-146" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-147"><a href="#cb1-147" aria-hidden="true" tabindex="-1"></a>While -- this is frequently used in papers.</span>
<span id="cb1-148"><a href="#cb1-148" aria-hidden="true" tabindex="-1"></a>What is this?</span>
<span id="cb1-149"><a href="#cb1-149" aria-hidden="true" tabindex="-1"></a><span class="ss">1. </span>Scores of relevance at each time step</span>
<span id="cb1-150"><a href="#cb1-150" aria-hidden="true" tabindex="-1"></a><span class="ss">2. </span>Dynamically generated</span>
<span id="cb1-151"><a href="#cb1-151" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-152"><a href="#cb1-152" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-153"><a href="#cb1-153" aria-hidden="true" tabindex="-1"></a><span class="fu">## Describing in plain english:</span></span>
<span id="cb1-154"><a href="#cb1-154" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-155"><a href="#cb1-155" aria-hidden="true" tabindex="-1"></a><span class="ss">1. </span>Encoder is containing, with all source tokens</span>
<span id="cb1-156"><a href="#cb1-156" aria-hidden="true" tabindex="-1"></a><span class="ss">2. </span>And, what are they doing?</span>
<span id="cb1-157"><a href="#cb1-157" aria-hidden="true" tabindex="-1"></a><span class="ss">3. </span>Look at each other, update representations</span>
<span id="cb1-158"><a href="#cb1-158" aria-hidden="true" tabindex="-1"></a><span class="ss">4. </span>Decoder is doing, look at target token at current time step (t)</span>
<span id="cb1-159"><a href="#cb1-159" aria-hidden="true" tabindex="-1"></a><span class="ss">5. </span>Look at previous target token, look at source representation</span>
<span id="cb1-160"><a href="#cb1-160" aria-hidden="true" tabindex="-1"></a><span class="ss">6. </span>Update representation</span>
<span id="cb1-161"><a href="#cb1-161" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-162"><a href="#cb1-162" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-163"><a href="#cb1-163" aria-hidden="true" tabindex="-1"></a><span class="fu">## Self-attention:</span></span>
<span id="cb1-164"><a href="#cb1-164" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-165"><a href="#cb1-165" aria-hidden="true" tabindex="-1"></a>Self-attention is a key-building block</span>
<span id="cb1-166"><a href="#cb1-166" aria-hidden="true" tabindex="-1"></a>What's the diff between self-attention vs attention?</span>
<span id="cb1-167"><a href="#cb1-167" aria-hidden="true" tabindex="-1"></a>Huh, Well - self-attention operates between representation of same nature</span>
<span id="cb1-168"><a href="#cb1-168" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-169"><a href="#cb1-169" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-170"><a href="#cb1-170" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-171"><a href="#cb1-171" aria-hidden="true" tabindex="-1"></a>Decoder-encoder attention is looking</span>
<span id="cb1-172"><a href="#cb1-172" aria-hidden="true" tabindex="-1"></a>From: one current decoder state</span>
<span id="cb1-173"><a href="#cb1-173" aria-hidden="true" tabindex="-1"></a>At: all encoder states</span>
<span id="cb1-174"><a href="#cb1-174" aria-hidden="true" tabindex="-1"></a>Self-attention is looking</span>
<span id="cb1-175"><a href="#cb1-175" aria-hidden="true" tabindex="-1"></a>From: each state from a set of states</span>
<span id="cb1-176"><a href="#cb1-176" aria-hidden="true" tabindex="-1"></a>At: All other states in same set</span>
<span id="cb1-177"><a href="#cb1-177" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-178"><a href="#cb1-178" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-179"><a href="#cb1-179" aria-hidden="true" tabindex="-1"></a>Query, Key and Value in Self-Attention:</span>
<span id="cb1-180"><a href="#cb1-180" aria-hidden="true" tabindex="-1"></a>QKV, is how we implement attention.</span>
<span id="cb1-181"><a href="#cb1-181" aria-hidden="true" tabindex="-1"></a>Each input token, in self-attention receives three representation</span>
<span id="cb1-182"><a href="#cb1-182" aria-hidden="true" tabindex="-1"></a>So- what do Q, K, V do?</span>
<span id="cb1-183"><a href="#cb1-183" aria-hidden="true" tabindex="-1"></a><span class="ss">1. </span>Query : I Ask for an information</span>
<span id="cb1-184"><a href="#cb1-184" aria-hidden="true" tabindex="-1"></a><span class="ss">2. </span>Key: I have some information</span>
<span id="cb1-185"><a href="#cb1-185" aria-hidden="true" tabindex="-1"></a><span class="ss">3. </span>Value: I give you the information</span>
<span id="cb1-186"><a href="#cb1-186" aria-hidden="true" tabindex="-1"></a>Query -- Tokens look at each other</span>
<span id="cb1-187"><a href="#cb1-187" aria-hidden="true" tabindex="-1"></a>Key -- Respond to Query's request</span>
<span id="cb1-188"><a href="#cb1-188" aria-hidden="true" tabindex="-1"></a>Value -- Compute Attention Output</span>
<span id="cb1-189"><a href="#cb1-189" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-190"><a href="#cb1-190" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-191"><a href="#cb1-191" aria-hidden="true" tabindex="-1"></a>Key idea to remember,</span>
<span id="cb1-192"><a href="#cb1-192" aria-hidden="true" tabindex="-1"></a>"Compare Query with Keys" to get, "Scores/Weights" for, "Values"</span>
<span id="cb1-193"><a href="#cb1-193" aria-hidden="true" tabindex="-1"></a><span class="ss">1. </span>Each Score/Weight is relevance between query, key</span>
<span id="cb1-194"><a href="#cb1-194" aria-hidden="true" tabindex="-1"></a><span class="ss">2. </span>Reweigh values with scores/weights</span>
<span id="cb1-195"><a href="#cb1-195" aria-hidden="true" tabindex="-1"></a><span class="ss">3. </span>Take summation of reweighed values</span>
<span id="cb1-196"><a href="#cb1-196" aria-hidden="true" tabindex="-1"></a>Multi-head Attention</span>
<span id="cb1-197"><a href="#cb1-197" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-198"><a href="#cb1-198" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-199"><a href="#cb1-199" aria-hidden="true" tabindex="-1"></a><span class="fu">## Multi-Head Attention:</span></span>
<span id="cb1-200"><a href="#cb1-200" aria-hidden="true" tabindex="-1"></a>The Building Block of Transformer Model:</span>
<span id="cb1-201"><a href="#cb1-201" aria-hidden="true" tabindex="-1"></a>In order to understand a word in a sentence,</span>
<span id="cb1-202"><a href="#cb1-202" aria-hidden="true" tabindex="-1"></a>It requires understanding, how is this word related in a sentence</span>
<span id="cb1-203"><a href="#cb1-203" aria-hidden="true" tabindex="-1"></a>eg: "Na Veetuku Porae" <span class="co">[</span><span class="ot">Tamil</span><span class="co">]</span> to I am going to my house <span class="co">[</span><span class="ot">English</span><span class="co">]</span></span>
<span id="cb1-204"><a href="#cb1-204" aria-hidden="true" tabindex="-1"></a>Requires knowing, "Veetuku" word, on how is it related to other words in a sentence.</span>
<span id="cb1-205"><a href="#cb1-205" aria-hidden="true" tabindex="-1"></a>So, Each word has relations</span>
<span id="cb1-206"><a href="#cb1-206" aria-hidden="true" tabindex="-1"></a>So Intuitively, Multi-head attention, lets the model focus on many things.</span>
<span id="cb1-207"><a href="#cb1-207" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-208"><a href="#cb1-208" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-209"><a href="#cb1-209" aria-hidden="true" tabindex="-1"></a>So, we split queries, keys, values of single-head attention into several parts.</span>
<span id="cb1-210"><a href="#cb1-210" aria-hidden="true" tabindex="-1"></a>In this way -- model with one attention head or several of them, have same size.</span>
<span id="cb1-211"><a href="#cb1-211" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-212"><a href="#cb1-212" aria-hidden="true" tabindex="-1"></a>Now for Transformer Model:</span>
<span id="cb1-213"><a href="#cb1-213" aria-hidden="true" tabindex="-1"></a>Source: Lena Voita's Blog</span>
<span id="cb1-214"><a href="#cb1-214" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-215"><a href="#cb1-215" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-216"><a href="#cb1-216" aria-hidden="true" tabindex="-1"></a><span class="fu"># So, What does it do?</span></span>
<span id="cb1-217"><a href="#cb1-217" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-218"><a href="#cb1-218" aria-hidden="true" tabindex="-1"></a><span class="ss">1. </span>Encoder -- token communicates with each other</span>
<span id="cb1-219"><a href="#cb1-219" aria-hidden="true" tabindex="-1"></a><span class="ss">2. </span>Update Representation</span>
<span id="cb1-220"><a href="#cb1-220" aria-hidden="true" tabindex="-1"></a><span class="ss">3. </span>Decoder, target token look at previously generate target token</span>
<span id="cb1-221"><a href="#cb1-221" aria-hidden="true" tabindex="-1"></a><span class="ss">4. </span>Update Representation</span>
<span id="cb1-222"><a href="#cb1-222" aria-hidden="true" tabindex="-1"></a><span class="ss">5. </span>We have 6 layers</span>
<span id="cb1-223"><a href="#cb1-223" aria-hidden="true" tabindex="-1"></a>Feed Forward Layer:</span>
<span id="cb1-224"><a href="#cb1-224" aria-hidden="true" tabindex="-1"></a>The Model uses FFL to update new information</span>
<span id="cb1-225"><a href="#cb1-225" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-226"><a href="#cb1-226" aria-hidden="true" tabindex="-1"></a><span class="fu">### Residual Connections:</span></span>
<span id="cb1-227"><a href="#cb1-227" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-228"><a href="#cb1-228" aria-hidden="true" tabindex="-1"></a>First time, I saw this - it was in Object detection papers.</span>
<span id="cb1-229"><a href="#cb1-229" aria-hidden="true" tabindex="-1"></a>Why use it?</span>
<span id="cb1-230"><a href="#cb1-230" aria-hidden="true" tabindex="-1"></a>Similar to skip-connection</span>
<span id="cb1-231"><a href="#cb1-231" aria-hidden="true" tabindex="-1"></a>Stabilize the network</span>
<span id="cb1-232"><a href="#cb1-232" aria-hidden="true" tabindex="-1"></a>Recall, when we have deeper neural networks, issues start ebbing out</span>
<span id="cb1-233"><a href="#cb1-233" aria-hidden="true" tabindex="-1"></a>"Vanishing Gradient" - suddenly, the training drops to, "Zero"</span>
<span id="cb1-234"><a href="#cb1-234" aria-hidden="true" tabindex="-1"></a>Imagine, you are in your house, lights are on, suddenly it becomes dark.</span>
<span id="cb1-235"><a href="#cb1-235" aria-hidden="true" tabindex="-1"></a>That's why, similar to Skip-connection, Residual connection</span>
<span id="cb1-236"><a href="#cb1-236" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-237"><a href="#cb1-237" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-238"><a href="#cb1-238" aria-hidden="true" tabindex="-1"></a>In Transformer:</span>
<span id="cb1-239"><a href="#cb1-239" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-240"><a href="#cb1-240" aria-hidden="true" tabindex="-1"></a>Residuals used after Attention and Feed Forward Neural Network block</span>
<span id="cb1-241"><a href="#cb1-241" aria-hidden="true" tabindex="-1"></a>Layer Normalization:</span>
<span id="cb1-242"><a href="#cb1-242" aria-hidden="true" tabindex="-1"></a>Norm in Transformer "Add &amp; Norm" is Layer Normalization</span>
<span id="cb1-243"><a href="#cb1-243" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-244"><a href="#cb1-244" aria-hidden="true" tabindex="-1"></a><span class="fu"># What does it do?</span></span>
<span id="cb1-245"><a href="#cb1-245" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-246"><a href="#cb1-246" aria-hidden="true" tabindex="-1"></a>Well, it normalizes, vector representation in batches</span>
<span id="cb1-247"><a href="#cb1-247" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-248"><a href="#cb1-248" aria-hidden="true" tabindex="-1"></a>So what?</span>
<span id="cb1-249"><a href="#cb1-249" aria-hidden="true" tabindex="-1"></a>Well, We want to manage flow to next layer</span>
<span id="cb1-250"><a href="#cb1-250" aria-hidden="true" tabindex="-1"></a>Layer normalization improves convergence stability and quality</span>
<span id="cb1-251"><a href="#cb1-251" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-252"><a href="#cb1-252" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-253"><a href="#cb1-253" aria-hidden="true" tabindex="-1"></a><span class="ss">1. </span>Normalize each vector representation of each token</span>
<span id="cb1-254"><a href="#cb1-254" aria-hidden="true" tabindex="-1"></a><span class="ss">2. </span>LayerNorm, has parameters - scale and bias</span>
<span id="cb1-255"><a href="#cb1-255" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-256"><a href="#cb1-256" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-257"><a href="#cb1-257" aria-hidden="true" tabindex="-1"></a><span class="fu">## Positional Encoding:</span></span>
<span id="cb1-258"><a href="#cb1-258" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-259"><a href="#cb1-259" aria-hidden="true" tabindex="-1"></a>Recall, we want some sort of representation for positions of tokens</span>
<span id="cb1-260"><a href="#cb1-260" aria-hidden="true" tabindex="-1"></a>Convolutional Layers or Recurrence Layers</span>
<span id="cb1-261"><a href="#cb1-261" aria-hidden="true" tabindex="-1"></a>They help to know position of tokens</span>
<span id="cb1-262"><a href="#cb1-262" aria-hidden="true" tabindex="-1"></a>But, in Transformer, we do not have either, So, we need something for positional representation.</span>
<span id="cb1-263"><a href="#cb1-263" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-264"><a href="#cb1-264" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-265"><a href="#cb1-265" aria-hidden="true" tabindex="-1"></a>Two embedding are required:</span>
<span id="cb1-266"><a href="#cb1-266" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-267"><a href="#cb1-267" aria-hidden="true" tabindex="-1"></a>Embedding, a way to translate words into magic vector form, so computers can understand</span>
<span id="cb1-268"><a href="#cb1-268" aria-hidden="true" tabindex="-1"></a>1) Tokens</span>
<span id="cb1-269"><a href="#cb1-269" aria-hidden="true" tabindex="-1"></a>2) Positions</span>
<span id="cb1-270"><a href="#cb1-270" aria-hidden="true" tabindex="-1"></a>So, input representation of token is sum of two embeddings:</span>
<span id="cb1-271"><a href="#cb1-271" aria-hidden="true" tabindex="-1"></a>Token and Positional</span>
<span id="cb1-272"><a href="#cb1-272" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-273"><a href="#cb1-273" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-274"><a href="#cb1-274" aria-hidden="true" tabindex="-1"></a>Pos is position.</span>
<span id="cb1-275"><a href="#cb1-275" aria-hidden="true" tabindex="-1"></a>i is vector dimension.</span>
<span id="cb1-276"><a href="#cb1-276" aria-hidden="true" tabindex="-1"></a>If you recall, trigonometry from your math teacher in high-school.</span>
<span id="cb1-277"><a href="#cb1-277" aria-hidden="true" tabindex="-1"></a>Trigonometric functions are helpful to represent angles, position.</span>
<span id="cb1-278"><a href="#cb1-278" aria-hidden="true" tabindex="-1"></a>How cool is it?</span>
<span id="cb1-279"><a href="#cb1-279" aria-hidden="true" tabindex="-1"></a>Positional Encoding, represents wavelengths in geometric progression from 2‚àè to 1000. 2‚àè.</span>
<span id="cb1-280"><a href="#cb1-280" aria-hidden="true" tabindex="-1"></a>Think this way - a way to represent positions through angles</span>
<span id="cb1-281"><a href="#cb1-281" aria-hidden="true" tabindex="-1"></a>So what?</span>
<span id="cb1-282"><a href="#cb1-282" aria-hidden="true" tabindex="-1"></a>eg: "Room la fan poddu" <span class="co">[</span><span class="ot">Tamil</span><span class="co">]</span> translates, Switch on Fan <span class="co">[</span><span class="ot">English</span><span class="co">]</span></span>
<span id="cb1-283"><a href="#cb1-283" aria-hidden="true" tabindex="-1"></a>"poddu" can be break or to turn on.</span>
<span id="cb1-284"><a href="#cb1-284" aria-hidden="true" tabindex="-1"></a>Positional Encoding, would help represent and retain both meanings.</span>
<span id="cb1-285"><a href="#cb1-285" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-286"><a href="#cb1-286" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-287"><a href="#cb1-287" aria-hidden="true" tabindex="-1"></a><span class="fu"># Tokenization:</span></span>
<span id="cb1-288"><a href="#cb1-288" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-289"><a href="#cb1-289" aria-hidden="true" tabindex="-1"></a><span class="fu"># What is it?</span></span>
<span id="cb1-290"><a href="#cb1-290" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-291"><a href="#cb1-291" aria-hidden="true" tabindex="-1"></a>A way to divide sequence of words into small pieces</span>
<span id="cb1-292"><a href="#cb1-292" aria-hidden="true" tabindex="-1"></a>Many types are there</span>
<span id="cb1-293"><a href="#cb1-293" aria-hidden="true" tabindex="-1"></a>So, "Poddu" <span class="co">[</span><span class="ot">Tamil</span><span class="co">]</span> word has both turn on, and to break meaning</span>
<span id="cb1-294"><a href="#cb1-294" aria-hidden="true" tabindex="-1"></a><span class="ss">1. </span>Word Level</span>
<span id="cb1-295"><a href="#cb1-295" aria-hidden="true" tabindex="-1"></a><span class="ss">2. </span>Sub-word Level</span>
<span id="cb1-296"><a href="#cb1-296" aria-hidden="true" tabindex="-1"></a>Word Level can only process fixed number of words, limited</span>
<span id="cb1-297"><a href="#cb1-297" aria-hidden="true" tabindex="-1"></a>Subword level can process open vocabulary, and unknown words</span>
<span id="cb1-298"><a href="#cb1-298" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-299"><a href="#cb1-299" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-300"><a href="#cb1-300" aria-hidden="true" tabindex="-1"></a>Baby step High-level differences between Encoder-Decoder in Transformer:</span>
<span id="cb1-301"><a href="#cb1-301" aria-hidden="true" tabindex="-1"></a>Encoder:</span>
<span id="cb1-302"><a href="#cb1-302" aria-hidden="true" tabindex="-1"></a><span class="ss">1. </span>Multi-head Attention</span>
<span id="cb1-303"><a href="#cb1-303" aria-hidden="true" tabindex="-1"></a>Decoder:</span>
<span id="cb1-304"><a href="#cb1-304" aria-hidden="true" tabindex="-1"></a><span class="ss">1. </span>Masked Multi-head Attention</span>
<span id="cb1-305"><a href="#cb1-305" aria-hidden="true" tabindex="-1"></a><span class="ss">2. </span>Scaled Dot-Product Attention</span>
<span id="cb1-306"><a href="#cb1-306" aria-hidden="true" tabindex="-1"></a>Recall, Masked Self-attention means, future tokens are masked out.</span>
<span id="cb1-307"><a href="#cb1-307" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-308"><a href="#cb1-308" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-309"><a href="#cb1-309" aria-hidden="true" tabindex="-1"></a>Another way to explain, more picture focused (Attention Layer):</span>
<span id="cb1-310"><a href="#cb1-310" aria-hidden="true" tabindex="-1"></a>GRU:</span>
<span id="cb1-311"><a href="#cb1-311" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-312"><a href="#cb1-312" aria-hidden="true" tabindex="-1"></a><span class="ss">1. </span>Recall, GRU is specialized form of RNN</span>
<span id="cb1-313"><a href="#cb1-313" aria-hidden="true" tabindex="-1"></a><span class="ss">2. </span>GRU has two gates <span class="co">[</span><span class="ot">reset, update</span><span class="co">]</span></span>
<span id="cb1-314"><a href="#cb1-314" aria-hidden="true" tabindex="-1"></a><span class="ss">3. </span>LSTM has three gates <span class="co">[</span><span class="ot">input, output, forget</span><span class="co">]</span></span>
<span id="cb1-315"><a href="#cb1-315" aria-hidden="true" tabindex="-1"></a>GRU, less complex than LSTM</span>
<span id="cb1-316"><a href="#cb1-316" aria-hidden="true" tabindex="-1"></a><span class="ss">4. </span>GRU, doesn't have memory unit compared with LSTM</span>
<span id="cb1-317"><a href="#cb1-317" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-318"><a href="#cb1-318" aria-hidden="true" tabindex="-1"></a>So in the picture,</span>
<span id="cb1-319"><a href="#cb1-319" aria-hidden="true" tabindex="-1"></a>Encoder-Decoder, dominant form of architecture in Seq2Seq task, cool right?</span>
<span id="cb1-320"><a href="#cb1-320" aria-hidden="true" tabindex="-1"></a>BiGRU, Bidirectional GRU, takes input in forward and other in backward direction</span>
<span id="cb1-321"><a href="#cb1-321" aria-hidden="true" tabindex="-1"></a>Green Dots -- Encoder Hidden State</span>
<span id="cb1-322"><a href="#cb1-322" aria-hidden="true" tabindex="-1"></a>Red Dots -- Decoder Hidden State</span>
<span id="cb1-323"><a href="#cb1-323" aria-hidden="true" tabindex="-1"></a>Why do we need Hidden State?</span>
<span id="cb1-324"><a href="#cb1-324" aria-hidden="true" tabindex="-1"></a>Squashing function, perform non-linear function in neural network</span>
<span id="cb1-325"><a href="#cb1-325" aria-hidden="true" tabindex="-1"></a>Blue dots -- Score</span>
<span id="cb1-326"><a href="#cb1-326" aria-hidden="true" tabindex="-1"></a>Softmax -- Sum of probability distribution equal to 1</span>
<span id="cb1-327"><a href="#cb1-327" aria-hidden="true" tabindex="-1"></a>Use Softmax only when in classifier, classes are mutually exclusive</span>
<span id="cb1-328"><a href="#cb1-328" aria-hidden="true" tabindex="-1"></a>Alignment Vector -- input at position j, and outputs at position i match</span>
<span id="cb1-329"><a href="#cb1-329" aria-hidden="true" tabindex="-1"></a>Context Vector -- Attention Score</span>
<span id="cb1-330"><a href="#cb1-330" aria-hidden="true" tabindex="-1"></a>Source: <span class="co">[</span><span class="ot">Teksands</span><span class="co">]</span></span>
<span id="cb1-331"><a href="#cb1-331" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-332"><a href="#cb1-332" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-333"><a href="#cb1-333" aria-hidden="true" tabindex="-1"></a>Scaled Dot Product Attention</span>
<span id="cb1-334"><a href="#cb1-334" aria-hidden="true" tabindex="-1"></a>Score = (1/‚àön) (decoder state) (encoder state)</span>
<span id="cb1-335"><a href="#cb1-335" aria-hidden="true" tabindex="-1"></a>Dot Product Attention:</span>
<span id="cb1-336"><a href="#cb1-336" aria-hidden="true" tabindex="-1"></a>Score = (decoder state) (encoder state)</span>
<span id="cb1-337"><a href="#cb1-337" aria-hidden="true" tabindex="-1"></a>Additive based Attention</span>
<span id="cb1-338"><a href="#cb1-338" aria-hidden="true" tabindex="-1"></a>Score = (decoder state) (encoder state) = trainable weights</span>
<span id="cb1-339"><a href="#cb1-339" aria-hidden="true" tabindex="-1"></a>Cosine Similarity based Attention:</span>
<span id="cb1-340"><a href="#cb1-340" aria-hidden="true" tabindex="-1"></a>Score = (decoder state) (encoder state) / norm <span class="co">[</span><span class="ot">(decoder state) (encoder state)</span><span class="co">]</span></span>
<span id="cb1-341"><a href="#cb1-341" aria-hidden="true" tabindex="-1"></a>Source: <span class="co">[</span><span class="ot">Teksands</span><span class="co">]</span></span>
<span id="cb1-342"><a href="#cb1-342" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-343"><a href="#cb1-343" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-344"><a href="#cb1-344" aria-hidden="true" tabindex="-1"></a><span class="fu"># BERT</span></span>
<span id="cb1-345"><a href="#cb1-345" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-346"><a href="#cb1-346" aria-hidden="true" tabindex="-1"></a><span class="ss">1. </span>Pre-trained Language Model from Google </span>
<span id="cb1-347"><a href="#cb1-347" aria-hidden="true" tabindex="-1"></a><span class="ss">2. </span>Most easy to use among all language models</span>
<span id="cb1-348"><a href="#cb1-348" aria-hidden="true" tabindex="-1"></a>BERT lead into developments in </span>
<span id="cb1-349"><a href="#cb1-349" aria-hidden="true" tabindex="-1"></a><span class="ss">1. </span>GPT (Decoder Block)</span>
<span id="cb1-350"><a href="#cb1-350" aria-hidden="true" tabindex="-1"></a><span class="ss">2. </span>GPT-2 (Decoder Block)</span>
<span id="cb1-351"><a href="#cb1-351" aria-hidden="true" tabindex="-1"></a><span class="ss">3. </span>GPT-3 (Decoder Block)</span>
<span id="cb1-352"><a href="#cb1-352" aria-hidden="true" tabindex="-1"></a>Where to start? </span>
<span id="cb1-353"><a href="#cb1-353" aria-hidden="true" tabindex="-1"></a>"Attention is all you need"</span>
<span id="cb1-354"><a href="#cb1-354" aria-hidden="true" tabindex="-1"></a>Paper: üìéhttps://arxiv.org/pdf/1706.03762.pdf</span>
<span id="cb1-355"><a href="#cb1-355" aria-hidden="true" tabindex="-1"></a>Tutorial: </span>
<span id="cb1-356"><a href="#cb1-356" aria-hidden="true" tabindex="-1"></a>https://nlp.seas.harvard.edu/2018/04/03/attention.html</span>
<span id="cb1-357"><a href="#cb1-357" aria-hidden="true" tabindex="-1"></a> Harvard NLP Professor Stuart Shieber's Blog üßµ</span>
<span id="cb1-358"><a href="#cb1-358" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-359"><a href="#cb1-359" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-360"><a href="#cb1-360" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-361"><a href="#cb1-361" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-362"><a href="#cb1-362" aria-hidden="true" tabindex="-1"></a><span class="fu"># Conclusion</span></span>
<span id="cb1-363"><a href="#cb1-363" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-364"><a href="#cb1-364" aria-hidden="true" tabindex="-1"></a>It is easy to create great looking documents using <span class="in">`quarto`</span>, whether that be with code in <span class="in">`python`</span> or <span class="in">`R`</span>. <span class="in">`Quarto`</span> supports most of the features in <span class="in">`RMarkdown`</span> with some fancy new ones. My personal favourite is the floating table of contents. I have also found that rendering a <span class="in">`Quarto`</span> blog is a much smoother experience than rendering a <span class="in">`blogdown`</span> blog.</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div></div></div></div></div>
</div> <!-- /content -->



</body></html>